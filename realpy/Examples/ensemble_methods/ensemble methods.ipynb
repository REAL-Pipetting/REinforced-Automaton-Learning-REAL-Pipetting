{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import color_functions\n",
    "from color_functions import new_spectra_from_stock\n",
    "from RL_functions import obtain_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Actual Data from Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_concentrations = pd.read_excel('Sample_concentrations.xlsx')\n",
    "red_conc = Sample_concentrations[['Red vol frac']].values\n",
    "green_conc = Sample_concentrations[['Green vol frac']].values\n",
    "blue_conc = Sample_concentrations[['Blue vol frac']].values\n",
    "sample_conc = np.hstack((red_conc, green_conc, blue_conc))\n",
    "y_train = sample_conc[0:-1,:]\n",
    "\n",
    "#Normalize y_train\n",
    "for j in range(y_train.shape[0]):\n",
    "    row_sum = np.sum(y_train[j,:])\n",
    "    for i in range(y_train.shape[1]):\n",
    "        y_train[j,i] = y_train[j,i]/row_sum\n",
    "\n",
    "sample_spectra = pd.read_excel('Sample_spectra.xlsx')\n",
    "sample_spectra = np.asarray(sample_spectra)\n",
    "x_train = sample_spectra[:,1:-1]\n",
    "x_test = sample_spectra[:,-1].reshape(-1,1)\n",
    "\n",
    "#Normalizae x_train\n",
    "x_train = MinMaxScaler().fit(x_train).transform(x_train)\n",
    "x_test = MinMaxScaler().fit(x_test).transform(x_test).T\n",
    "x_train = x_train.T\n",
    "x_test = x_test.reshape(1,-1)[0].reshape(-1,1).T\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "x_train_new = pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "prediction_array = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeRegressor(max_depth= 79)\n",
    "clf = BaggingRegressor(base_estimator=estimator, n_estimators=56)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "prediction_array = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.53449712, 0.00775591, 0.49257213]]), array([0.08186359]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr = GaussianProcessRegressor().fit(x_train, y_train)\n",
    "gpr.predict(x_test, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4797501061127716\n",
      "0.022024790114073697\n",
      "0.4982251037731548\n"
     ]
    }
   ],
   "source": [
    "regr = MLPRegressor(max_iter=500).fit(x_train, y_train)\n",
    "prediction_nn = regr.predict(x_test)\n",
    "red_prediction_nn = prediction_nn[0][0]\n",
    "green_prediction_nn = prediction_nn[0][1]\n",
    "blue_prediction_nn = prediction_nn[0][2]\n",
    "sum_prediction_nn = np.sum(prediction_nn[0])\n",
    "print(red_prediction_nn/sum_prediction_nn)\n",
    "print(green_prediction_nn/sum_prediction_nn)\n",
    "print(blue_prediction_nn/sum_prediction_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Performance of each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y_train = []\n",
    "dtr_y_train = []\n",
    "lr_y_train = []\n",
    "gpr_y_train = [] \n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    prediction_nn = regr.predict(np.array([x_train[i,:]]))\n",
    "    nn_y_train.append(prediction_nn[0])\n",
    "    prediction_dtr = clf.predict(np.array([x_train[i,:]]))\n",
    "    dtr_y_train.append(prediction_dtr[0])\n",
    "    prediction_lr = reg.predict(np.array([x_train[i,:]]))\n",
    "    lr_y_train.append(prediction_lr[0])\n",
    "    prediction_gpr = gpr.predict(np.array([x_train[i,:]]))\n",
    "    gpr_y_train.append(prediction_gpr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y_train_array = nn_y_train[0]\n",
    "for i in range(1,len(nn_y_train)):\n",
    "    nn_y_train_array = np.vstack((nn_y_train_array, nn_y_train[i]))\n",
    "\n",
    "dtr_y_train_array = dtr_y_train[0]\n",
    "for i in range(1,len(dtr_y_train)):\n",
    "    dtr_y_train_array = np.vstack((dtr_y_train_array, dtr_y_train[i]))\n",
    "\n",
    "lr_y_train_array = lr_y_train[0]\n",
    "for i in range(1,len(lr_y_train)):\n",
    "    lr_y_train_array = np.vstack((lr_y_train_array, lr_y_train[i]))\n",
    "\n",
    "gpr_y_train_array = gpr_y_train[0]\n",
    "for i in range(1,len(gpr_y_train)):\n",
    "    gpr_y_train_array = np.vstack((gpr_y_train_array, gpr_y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare the predicted concentration dataset to the actual\n",
      "MSE of neural network: 0.06554210806768139\n",
      "MSE of decision tree regressor: 0.3430122434887773\n",
      "MSE of linear regressor: 0.12320290151219522\n",
      "MSE of gaussian process regressor: 2.8321745802036165e-16\n"
     ]
    }
   ],
   "source": [
    "print('Compare the predicted concentration dataset to the actual')\n",
    "print('MSE of neural network:', np.sum((nn_y_train_array - y_train)**2))\n",
    "print('MSE of decision tree regressor:', np.sum((dtr_y_train_array - y_train)**2))\n",
    "print('MSE of linear regressor:', np.sum((lr_y_train_array - y_train)**2))\n",
    "print('MSE of gaussian process regressor:', np.sum((gpr_y_train_array - y_train)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectra Generator for RBG Dyes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = obtain_data(50)\n",
    "Sample_concentrations = pd.read_excel('Sample_concentrations.xlsx')\n",
    "red_conc = Sample_concentrations[['Red conc']].values\n",
    "green_conc = Sample_concentrations[['Green conc']].values\n",
    "blue_conc = Sample_concentrations[['Blue conc']].values\n",
    "sample_conc = np.hstack((red_conc, green_conc, blue_conc))\n",
    "sample_spectra = pd.read_excel('Sample_spectra.xlsx')\n",
    "sample_spectra = np.asarray(sample_spectra)\n",
    "wavelength = sample_spectra[:,0]\n",
    "red = sample_spectra[:,1]\n",
    "green = sample_spectra[:,2]\n",
    "blue = sample_spectra[:,3]\n",
    "spectra = []\n",
    "for i in range(x.shape[0]):\n",
    "    spectra.append(new_spectra_from_stock(x[i,0],x[i,1],x[i,2] , red, green, blue, wavelength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra0 = spectra[0]\n",
    "for i in range(1,len(y)):\n",
    "    spectra0 = np.vstack((spectra0,spectra[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = spectra0 #spectra \n",
    "y_train = x #concentrations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99)\n",
    "x_train_new = pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = sample_spectra[:,-1].reshape(-1,1)\n",
    "x_test = MinMaxScaler().fit(x_test).transform(x_test).T\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GP Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr = GaussianProcessRegressor().fit(x_train, y_train)\n",
    "prediction_gpr = gpr.predict(x_test, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_prediction_gpr = prediction_gpr[0][0][0]\n",
    "green_prediction_gpr = prediction_gpr[0][0][1]\n",
    "blue_prediction_gpr = prediction_gpr[0][0][2]\n",
    "sum_prediction_gpr = np.sum(prediction_gpr[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37184777932200014\n",
      "0.33618538261692427\n",
      "0.29196683806107554\n"
     ]
    }
   ],
   "source": [
    "print(red_prediction_gpr/sum_prediction_gpr)\n",
    "print(green_prediction_gpr/sum_prediction_gpr)\n",
    "print(blue_prediction_gpr/sum_prediction_gpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "prediction_lr = reg.predict(x_test)\n",
    "red_prediction_lr = prediction_lr[0][0]\n",
    "green_prediction_lr = prediction_lr[0][1]\n",
    "blue_prediction_lr = prediction_lr[0][2]\n",
    "sum_prediction_lr = np.sum(prediction_lr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5180415502656843\n",
      "-0.04837885156910791\n",
      "0.5303373013034236\n"
     ]
    }
   ],
   "source": [
    "print(red_prediction_lr/sum_prediction_lr)\n",
    "print(green_prediction_lr/sum_prediction_lr)\n",
    "print(blue_prediction_lr/sum_prediction_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeRegressor(max_depth=27)\n",
    "clf = BaggingRegressor(base_estimator=estimator, n_estimators=43)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "prediction_dtr = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46082033537068096\n",
      "0.13239639605315798\n",
      "0.4067832685761611\n"
     ]
    }
   ],
   "source": [
    "red_prediction_dtr = prediction_dtr[0][0]\n",
    "green_prediction_dtr = prediction_dtr[0][1]\n",
    "blue_prediction_dtr = prediction_dtr[0][2]\n",
    "sum_prediction_dtr = np.sum(prediction_dtr[0])\n",
    "print(red_prediction_dtr/sum_prediction_dtr)\n",
    "print(green_prediction_dtr/sum_prediction_dtr)\n",
    "print(blue_prediction_dtr/sum_prediction_dtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor(max_iter=500).fit(x_train, y_train)\n",
    "prediction_nn = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4818201797272399\n",
      "0.14177108881802467\n",
      "0.3764087314547355\n"
     ]
    }
   ],
   "source": [
    "red_prediction_nn = prediction_nn[0][0]\n",
    "green_prediction_nn = prediction_nn[0][1]\n",
    "blue_prediction_nn = prediction_nn[0][2]\n",
    "sum_prediction_nn = np.sum(prediction_nn[0])\n",
    "print(red_prediction_nn/sum_prediction_nn)\n",
    "print(green_prediction_nn/sum_prediction_nn)\n",
    "print(blue_prediction_nn/sum_prediction_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE of each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y_train = []\n",
    "dtr_y_train = []\n",
    "lr_y_train = []\n",
    "gpr_y_train = [] \n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    prediction_nn = regr.predict(np.array([x_train[i,:]]))\n",
    "    nn_y_train.append(prediction_nn[0])\n",
    "    prediction_dtr = clf.predict(np.array([x_train[i,:]]))\n",
    "    dtr_y_train.append(prediction_dtr[0])\n",
    "    prediction_lr = reg.predict(np.array([x_train[i,:]]))\n",
    "    lr_y_train.append(prediction_lr[0])\n",
    "    prediction_gpr = gpr.predict(np.array([x_train[i,:]]))\n",
    "    gpr_y_train.append(prediction_gpr[0])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y_train_array = nn_y_train[0]\n",
    "for i in range(1,len(nn_y_train)):\n",
    "    nn_y_train_array = np.vstack((nn_y_train_array, nn_y_train[i]))\n",
    "\n",
    "dtr_y_train_array = dtr_y_train[0]\n",
    "for i in range(1,len(dtr_y_train)):\n",
    "    dtr_y_train_array = np.vstack((dtr_y_train_array, dtr_y_train[i]))\n",
    "\n",
    "lr_y_train_array = lr_y_train[0]\n",
    "for i in range(1,len(lr_y_train)):\n",
    "    lr_y_train_array = np.vstack((lr_y_train_array, lr_y_train[i]))\n",
    "\n",
    "gpr_y_train_array = gpr_y_train[0]\n",
    "for i in range(1,len(gpr_y_train)):\n",
    "    gpr_y_train_array = np.vstack((gpr_y_train_array, gpr_y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare the predicted concentration dataset to the actual\n",
      "MSE of neural network: 1.4429936778609231\n",
      "MSE of decision tree regressor: 0.2500033475177036\n",
      "MSE of linear regressor: 4.6484245137730325e-30\n",
      "MSE of gaussian process regressor: 2.0850025844287215e-19\n"
     ]
    }
   ],
   "source": [
    "print('Compare the predicted concentration dataset to the actual')\n",
    "print('MSE of neural network:', np.sum((nn_y_train_array - y_train)**2))\n",
    "print('MSE of decision tree regressor:', np.sum((dtr_y_train_array - y_train)**2))\n",
    "print('MSE of linear regressor:', np.sum((lr_y_train_array - y_train)**2))\n",
    "print('MSE of gaussian process regressor:', np.sum((gpr_y_train_array - y_train)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with actual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_concentrations = pd.read_excel('Sample_concentrations.xlsx')\n",
    "red_conc = Sample_concentrations[['Red vol frac']].values\n",
    "green_conc = Sample_concentrations[['Green vol frac']].values\n",
    "blue_conc = Sample_concentrations[['Blue vol frac']].values\n",
    "sample_conc = np.hstack((red_conc, green_conc, blue_conc))\n",
    "y_train = sample_conc[0:-1,:]\n",
    "\n",
    "#Normalize y_train\n",
    "for j in range(y_train.shape[0]):\n",
    "    row_sum = np.sum(y_train[j,:])\n",
    "    for i in range(y_train.shape[1]):\n",
    "        y_train[j,i] = y_train[j,i]/row_sum\n",
    "\n",
    "sample_spectra = pd.read_excel('Sample_spectra.xlsx')\n",
    "sample_spectra = np.asarray(sample_spectra)\n",
    "x_train = sample_spectra[:,1:-1]\n",
    "x_test = sample_spectra[:,-1].reshape(-1,1)\n",
    "\n",
    "#Normalizae x_train\n",
    "x_train = MinMaxScaler().fit(x_train).transform(x_train)\n",
    "x_test = MinMaxScaler().fit(x_test).transform(x_test).T\n",
    "x_train = x_train.T\n",
    "x_test = x_test.reshape(1,-1)[0].reshape(-1,1).T\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "x_train_new = pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_gpr = gpr.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lr = reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dtr = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_nn = regr.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of GPR: 6.782500593252865\n",
      "MSE of LR: 6.840778948942412\n",
      "MSE of DTR: 6.857393791187935\n",
      "MSE of NN: 5.804235096937878\n"
     ]
    }
   ],
   "source": [
    "print('MSE of GPR:', np.sum((y_train - prediction_gpr)**2))\n",
    "print('MSE of LR:', np.sum((y_train - prediction_lr)**2))\n",
    "print('MSE of DTR:', np.sum((y_train - prediction_dtr)**2))\n",
    "print('MSE of NN:', np.sum((y_train - prediction_nn)**2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
